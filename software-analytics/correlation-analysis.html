
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>1. Always handle collinearity and multicollinearity &#8212; The Software Analytics Cookbook</title>
    
  <link rel="stylesheet" href="../_static/css/index.f658d18f9b420779cfdf24aa0a7e2d77.css">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      
  <link rel="stylesheet"
    href="../_static/vendor/open-sans_all/1.44.1/index.css">
  <link rel="stylesheet"
    href="../_static/vendor/lato_latin-ext/1.44.1/index.css">

    
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/sphinx-book-theme.e7340bb3dbd8dde6db86f25597f54a1b.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.d3f166471bb80abb5163.js">

    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/sphinx-book-theme.7d483ff0a819d6edff12ce0b1ead3928.js"></script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    <link rel="canonical" href="https://analytics-cookbook.github.io/software-analytics/correlation-analysis.html" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="2. Always handle class imbalance" href="class-imbalance.html" />
    <link rel="prev" title="3. Defect Prediction Models" href="../start/defect-prediction.html" />

    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />


<!-- Opengraph tags -->
<meta property="og:url"         content="https://analytics-cookbook.github.io/software-analytics/correlation-analysis.html" />
<meta property="og:type"        content="article" />
<meta property="og:title"       content="Always handle collinearity and multicollinearity" />
<meta property="og:description" content="Always handle collinearity and multicollinearity  Collinearity (Pairwise Correlation)  Collinearity is a phenomenon in which one metric can be linearly predicte" />


<meta name="twitter:card" content="summary" />


  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="../index.html">
  
  
  <h1 class="site-logo" id="site-title">The Software Analytics Cookbook</h1>
  
</a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form>
<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
    <p class="caption collapsible-parent">
 <span class="caption-text">
  Getting Started
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../start/index.html">
   1. Software Analytics in a Nutshell
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../start/software-quality-assurance.html">
   2. Software Quality Assurance
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../start/defect-prediction.html">
   3. Defect Prediction Models
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Part1-Software Analytics Recipes
 </span>
</p>
<ul class="current nav sidenav_l1">
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   1. Always handle collinearity and multicollinearity
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="class-imbalance.html">
   2. Always handle class imbalance
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="classification.html">
   3. Always find the best classification technique
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="parameter-settings.html">
   4. Always optimize hyperparameter settings
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="model-validation.html">
   5. Avoid using testing dataset in model training
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="evaluation-measures.html">
   6. Always evaluate using business-driven measures
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="ranking-and-multiple-comparison.html">
   7. Using a Non-Parametric Scott-Knott ESD Test For Multiple Comparison
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Part2-Explainable AI for SE
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../xai4se/index.html">
   1. Introduction
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../xai4se/explainability-in-se.html">
   2. Explainability in Software Engineering
  </a>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../xai4se/model-level/Model-level.html">
   3. Model-level
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../xai4se/model-level/ANOVA.html">
     3.1. ANOVA analysis
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../xai4se/model-level/VarImp.html">
     3.2. Variable Importance analysis
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../xai4se/model-level/PDP.html">
     3.3. Partial Dependence Plot (PDP)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../xai4se/model-level/DTDR.html">
     3.4. Decision Tree/Decision Rules
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../xai4se/instance-level/Instance-level.html">
   4. Instance-level
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../xai4se/instance-level/LIME.html">
     4.1. LIME
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../xai4se/instance-level/SHAP.html">
     4.2. SHAP
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../xai4se/actionable-analytics.html">
   5. Please Tell Me What To Do!
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Part3-Case Study Examples
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../examples/defect-prediction.html">
   1. Defect Prediction
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Appendix
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../references.html">
   1. References
  </a>
 </li>
</ul>

</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../_sources/software-analytics/correlation-analysis.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/analytics-cookbook/analytics-cookbook.github.io"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://github.com/analytics-cookbook/analytics-cookbook.github.io/issues/new?title=Issue%20on%20page%20%2Fsoftware-analytics/correlation-analysis.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        <a class="edit-button" href="https://github.com/analytics-cookbook/analytics-cookbook.github.io/edit/master/docs/software-analytics/correlation-analysis.ipynb"><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Edit this page"><i class="fas fa-pencil-alt"></i>suggest edit</button></a>
    </div>
</div>


            <!-- Full screen (wrap in <a> to have style consistency -->
            <a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
                    data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
                    title="Fullscreen mode"><i
                        class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/analytics-cookbook/analytics-cookbook.github.io/master?urlpath=tree/docs/software-analytics/correlation-analysis.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="../_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        <a class="colab-button" href="https://colab.research.google.com/github/analytics-cookbook/analytics-cookbook.github.io/blob/master/docs/software-analytics/correlation-analysis.ipynb"><button type="button" class="btn btn-secondary topbarbtn"
                title="Launch Colab" data-toggle="tooltip" data-placement="left"><img class="colab-button-logo"
                    src="../_static/images/logo_colab.png"
                    alt="Interact on Colab">Colab</button></a>
        
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show">
            
        <div class="tocsection onthispage pt-5 pb-3">
            <i class="fas fa-list"></i>
            Contents
        </div>
        <nav id="bd-toc-nav">
            <ul class="nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#collinearity-pairwise-correlation">
   1.1. Collinearity (Pairwise Correlation)
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#multicollinearity">
   1.2. Multicollinearity
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#feature-selection-techniques-often-do-not-mitigate-collinearity-and-multicollinearity">
   1.3. Feature selection techniques often do not mitigate collinearity and multicollinearity!
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#filter-based-family">
     Filter-based Family
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#wrapper-based-family">
     Wrapper-based Family
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#autospearman-an-automated-feature-selection-approach-that-address-collinearity-and-multicollinearity">
   1.4. AutoSpearman: An automated feature selection approach that address collinearity and multicollinearity
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#suggested-readings">
     Suggested Readings
    </a>
   </li>
  </ul>
 </li>
</ul>

        </nav>
        
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="always-handle-collinearity-and-multicollinearity">
<h1><span class="section-number">1. </span>Always handle collinearity and multicollinearity<a class="headerlink" href="#always-handle-collinearity-and-multicollinearity" title="Permalink to this headline">¶</a></h1>
<div class="section" id="collinearity-pairwise-correlation">
<h2><span class="section-number">1.1. </span>Collinearity (Pairwise Correlation)<a class="headerlink" href="#collinearity-pairwise-correlation" title="Permalink to this headline">¶</a></h2>
<p>Collinearity is a phenomenon in which one metric can be linearly predicted by another metric.
There are several correlation tests that can detect collinearity between metrics. For example, Pearson correlation test, Spearman correlation test, and Kendall Tau correlation test.
Below, we provide a tutorial for using and visualising Spearman correlation test.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Import for Correlation tests</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">random</span>

<span class="c1"># Prepare a dataframe for collinearity simulation</span>
<span class="n">X_Corr</span> <span class="o">=</span> <span class="n">X_train</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>

<span class="c1"># Simulate a collinearity situation of AddedLOC and A</span>
<span class="n">X_Corr</span><span class="p">[</span><span class="s1">&#39;A&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="mi">2</span> <span class="o">*</span> <span class="n">x_i</span> <span class="o">+</span> <span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">()</span> <span class="k">for</span> <span class="n">x_i</span> <span class="ow">in</span> <span class="n">X_Corr</span><span class="p">[</span><span class="s1">&#39;AddedLOC&#39;</span><span class="p">]]</span>


<span class="c1"># There are 3 options for the parameter setting of method as follows:</span>
<span class="c1"># pearson : standard correlation coefficient</span>
<span class="c1"># kendall : Kendall Tau correlation coefficient</span>
<span class="c1"># spearman : Spearman rank correlation</span>
<span class="n">corrmat</span> <span class="o">=</span> <span class="n">X_Corr</span><span class="o">.</span><span class="n">corr</span><span class="p">(</span><span class="n">method</span><span class="o">=</span><span class="s1">&#39;spearman&#39;</span><span class="p">)</span>
<span class="n">top_corr_features</span> <span class="o">=</span> <span class="n">corrmat</span><span class="o">.</span><span class="n">index</span>


<span class="c1"># Visualise a lower-triangle correlation heatmap</span>
<span class="n">mask_df</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">triu</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">corrmat</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">bool</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">8</span><span class="p">))</span>
<span class="c1">#plot heat map</span>
<span class="n">g</span><span class="o">=</span><span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">X_Corr</span><span class="p">[</span><span class="n">top_corr_features</span><span class="p">]</span><span class="o">.</span><span class="n">corr</span><span class="p">(),</span> 
              <span class="n">mask</span> <span class="o">=</span> <span class="n">mask_df</span><span class="p">,</span> 
              <span class="n">vmin</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
              <span class="n">vmax</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
              <span class="n">annot</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
              <span class="n">cmap</span><span class="o">=</span><span class="s2">&quot;RdBu&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/correlation-analysis_3_0.png" src="../_images/correlation-analysis_3_0.png" />
</div>
</div>
</div>
<div class="section" id="multicollinearity">
<h2><span class="section-number">1.2. </span>Multicollinearity<a class="headerlink" href="#multicollinearity" title="Permalink to this headline">¶</a></h2>
<p>Multicollinearity is a phenomenon in which one metric can be linearly predicted by a combination of two or more metrics.
Multicollinearity can be detected using Variance Inflation Factor (VIF) analysis <span id="id1">[<a class="reference internal" href="../references.html#id69"><span>FM92</span></a>]</span>.
The idea behind variance inflation factor analysis is to construct an ordinary least square regression to predict a metric by using the other metrics in the dataset.
Having a model that is well fit indicates that the metric can be predicted by other metrics, linearly highly-correlated with other metrics.
There are 3 steps in variance inflation factor analysis.</p>
<p><em>(Step 1) Construct a regression model for each metric.</em>
For each metric, we construct a model using the other metrics to predict that particular metric.</p>
<p><em>(Step 2) Compute a VIF score for each metric.</em>
The VIF score for each metric is computed using the following formula: <span class="math notranslate nohighlight">\(\mathrm{VIF} = \frac{1}{1 - \mathrm{R}^2}\)</span>, where <span class="math notranslate nohighlight">\(\mathrm{R}^2\)</span> is the explanatory power of the regression model from Step 1.
A high VIF score of a metric indicates that a given metric can be accurately predicted by the other metrics.
Thus, that given metric is considered redundant and should be removed from our model.</p>
<p><em>(Step 3) Remove metrics with a VIF score that is higher than a given threshold.</em>
We remove metrics with a VIF score that is higher than a given threshold.
We use a VIF threshold of 5 to determine the magnitude of multi-collinearity, as it is suggested by Fox <span id="id2">[<a class="reference internal" href="../references.html#id70"><span>Fox15</span></a>]</span>.
Then, we repeat the above three steps until the VIF scores of all remaining metrics are lower than the pre-defined threshold.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Import for VIF</span>
<span class="kn">from</span> <span class="nn">statsmodels.stats.outliers_influence</span> <span class="kn">import</span> <span class="n">variance_inflation_factor</span>
<span class="kn">from</span> <span class="nn">statsmodels.tools.tools</span> <span class="kn">import</span> <span class="n">add_constant</span>


<span class="c1"># Prepare a dataframe for VIF</span>
<span class="n">X_VIF</span> <span class="o">=</span> <span class="n">add_constant</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>

<span class="c1"># Simulate a multicollinearity situation of AddedLOC, A, and B</span>
<span class="n">X_VIF</span><span class="p">[</span><span class="s1">&#39;A&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="mi">2</span> <span class="o">*</span> <span class="n">x_i</span> <span class="o">+</span> <span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">()</span> <span class="k">for</span> <span class="n">x_i</span> <span class="ow">in</span> <span class="n">X_VIF</span><span class="p">[</span><span class="s1">&#39;AddedLOC&#39;</span><span class="p">]]</span>
<span class="n">X_VIF</span><span class="p">[</span><span class="s1">&#39;B&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="mi">3</span> <span class="o">*</span> <span class="n">x_i</span> <span class="o">+</span> <span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">()</span> <span class="k">for</span> <span class="n">x_i</span> <span class="ow">in</span> <span class="n">X_VIF</span><span class="p">[</span><span class="s1">&#39;AddedLOC&#39;</span><span class="p">]]</span>

<span class="c1"># Calculate VIF scores</span>
<span class="n">vif_scores</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">([</span><span class="n">variance_inflation_factor</span><span class="p">(</span><span class="n">X_VIF</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span> 
               <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">X_VIF</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])],</span> 
              <span class="n">index</span><span class="o">=</span><span class="n">X_VIF</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span>
<span class="c1"># Prepare a final dataframe of VIF scores</span>
<span class="n">vif_scores</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">inplace</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
<span class="n">vif_scores</span><span class="o">.</span><span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;Feature&#39;</span><span class="p">,</span> <span class="s1">&#39;VIFscore&#39;</span><span class="p">]</span>
<span class="n">vif_scores</span> <span class="o">=</span> <span class="n">vif_scores</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">vif_scores</span><span class="p">[</span><span class="s1">&#39;Feature&#39;</span><span class="p">]</span> <span class="o">!=</span> <span class="s1">&#39;const&#39;</span><span class="p">,</span> <span class="p">:]</span>
<span class="n">vif_scores</span> <span class="o">=</span> <span class="n">vif_scores</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">by</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;VIFscore&#39;</span><span class="p">],</span> <span class="n">ascending</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span>
<span class="n">vif_scores</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Feature</th>
      <th>VIFscore</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2</th>
      <td>AddedLOC</td>
      <td>3.363851e+06</td>
    </tr>
    <tr>
      <th>7</th>
      <td>B</td>
      <td>2.421962e+06</td>
    </tr>
    <tr>
      <th>6</th>
      <td>A</td>
      <td>1.078763e+06</td>
    </tr>
    <tr>
      <th>3</th>
      <td>nCoupledClass</td>
      <td>1.220642e+00</td>
    </tr>
    <tr>
      <th>5</th>
      <td>CommentToCodeRatio</td>
      <td>1.126280e+00</td>
    </tr>
    <tr>
      <th>1</th>
      <td>nCommit</td>
      <td>1.044982e+00</td>
    </tr>
    <tr>
      <th>4</th>
      <td>LOC</td>
      <td>1.019733e+00</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>In this example, we observe that LOC, A, and B are problematic with the VIF scores of above 5.
To mitigate multicollinearity, we need to exclude one metric with the highest VIF score, i.e., LOC.
We iteratively repeat the process as described above.</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Import for VIF</span>
<span class="kn">from</span> <span class="nn">statsmodels.stats.outliers_influence</span> <span class="kn">import</span> <span class="n">variance_inflation_factor</span>
<span class="kn">from</span> <span class="nn">statsmodels.tools.tools</span> <span class="kn">import</span> <span class="n">add_constant</span>
<span class="kn">import</span> <span class="nn">random</span>

<span class="c1"># Prepare a dataframe for VIF</span>
<span class="n">X_VIF</span> <span class="o">=</span> <span class="n">add_constant</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>

<span class="c1"># Simulate a multicollinearity situation of AddedLOC, A, and B</span>
<span class="n">X_VIF</span><span class="p">[</span><span class="s1">&#39;A&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="mi">2</span> <span class="o">*</span> <span class="n">x_i</span> <span class="o">+</span> <span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">()</span> <span class="k">for</span> <span class="n">x_i</span> <span class="ow">in</span> <span class="n">X_VIF</span><span class="p">[</span><span class="s1">&#39;AddedLOC&#39;</span><span class="p">]]</span>
<span class="n">X_VIF</span><span class="p">[</span><span class="s1">&#39;B&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="mi">3</span> <span class="o">*</span> <span class="n">x_i</span> <span class="o">+</span> <span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">()</span> <span class="k">for</span> <span class="n">x_i</span> <span class="ow">in</span> <span class="n">X_VIF</span><span class="p">[</span><span class="s1">&#39;AddedLOC&#39;</span><span class="p">]]</span>


<span class="n">selected_features</span> <span class="o">=</span> <span class="n">X_VIF</span><span class="o">.</span><span class="n">columns</span>

<span class="c1"># Stepwise-VIF</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Stepwise VIF START&#39;</span><span class="p">)</span>
<span class="n">count</span> <span class="o">=</span> <span class="mi">1</span>
<span class="k">while</span> <span class="kc">True</span><span class="p">:</span>
    <span class="c1"># Calculate VIF scores</span>
    <span class="n">vif_scores</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">([</span><span class="n">variance_inflation_factor</span><span class="p">(</span><span class="n">X_VIF</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span> 
                   <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">X_VIF</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])],</span> 
                  <span class="n">index</span><span class="o">=</span><span class="n">X_VIF</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span>
    <span class="c1"># Prepare a final dataframe of VIF scores</span>
    <span class="n">vif_scores</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">inplace</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
    <span class="n">vif_scores</span><span class="o">.</span><span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;Feature&#39;</span><span class="p">,</span> <span class="s1">&#39;VIFscore&#39;</span><span class="p">]</span>
    <span class="n">vif_scores</span> <span class="o">=</span> <span class="n">vif_scores</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">vif_scores</span><span class="p">[</span><span class="s1">&#39;Feature&#39;</span><span class="p">]</span> <span class="o">!=</span> <span class="s1">&#39;const&#39;</span><span class="p">,</span> <span class="p">:]</span>
    <span class="n">vif_scores</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">by</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;VIFscore&#39;</span><span class="p">],</span> <span class="n">ascending</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> <span class="n">inplace</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
    
    <span class="c1"># Find features that have their VIF scores of above 5.0</span>
    <span class="n">filtered_vif_scores</span> <span class="o">=</span> <span class="n">vif_scores</span><span class="p">[</span><span class="n">vif_scores</span><span class="p">[</span><span class="s1">&#39;VIFscore&#39;</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="mf">5.0</span><span class="p">]</span>
    
    <span class="c1"># Terminate when there is no features with the VIF scores of above 5.0</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">filtered_vif_scores</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">break</span>
        
    <span class="c1"># exclude the metric with the highest VIF score</span>
    <span class="n">metric_to_exclude</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">filtered_vif_scores</span><span class="p">[</span><span class="s1">&#39;Feature&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">1</span><span class="p">))[</span><span class="mi">0</span><span class="p">]</span>
    
    
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Step&#39;</span><span class="p">,</span> <span class="n">count</span><span class="p">,</span><span class="s1">&#39;- exclude&#39;</span><span class="p">,</span> <span class="nb">str</span><span class="p">(</span><span class="n">metric_to_exclude</span><span class="p">))</span>
    <span class="n">count</span> <span class="o">=</span> <span class="n">count</span> <span class="o">+</span> <span class="mi">1</span>
        
    <span class="n">selected_features</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">selected_features</span><span class="p">)</span> <span class="o">-</span> <span class="nb">set</span><span class="p">([</span><span class="n">metric_to_exclude</span><span class="p">]))</span>
    
    <span class="n">X_VIF</span> <span class="o">=</span> <span class="n">X_VIF</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="n">selected_features</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;The following features are selected according to Stepwise VIF with the VIF threshold value of 5:&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">vif_scores</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Stepwise VIF START
Step 1 - exclude AddedLOC
Step 2 - exclude B
The following features are selected according to Stepwise VIF with the VIF threshold value of 5:
              Feature  VIFscore
4       nCoupledClass  1.220647
5                   A  1.122400
2  CommentToCodeRatio  1.120934
3             nCommit  1.039827
0                 LOC  1.017052
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="feature-selection-techniques-often-do-not-mitigate-collinearity-and-multicollinearity">
<h2><span class="section-number">1.3. </span>Feature selection techniques often do not mitigate collinearity and multicollinearity!<a class="headerlink" href="#feature-selection-techniques-often-do-not-mitigate-collinearity-and-multicollinearity" title="Permalink to this headline">¶</a></h2>
<p>Feature selection is a data preprocessing technique for selecting a
subset of the best software metrics prior to constructing a defect
model. There is a plethora of feature selection techniques that can be
applied <span id="id3">[<a class="reference internal" href="../references.html#id83"><span>GE03</span></a>]</span>, e.g., filter-based, wrapper-based, and
embedded-based families.</p>
<div class="section" id="filter-based-family">
<h3>Filter-based Family<a class="headerlink" href="#filter-based-family" title="Permalink to this headline">¶</a></h3>
<p>Filter-based feature selection techniques search for the best subset of
metrics according to an evaluation criterion regardless of model
construction. Since constructing models is not required, the use of
filter-based feature selection techniques is considered low cost and
widely used.</p>
<p><strong>Chi-Squared-based feature selection</strong> <span id="id4">[<a class="reference internal" href="../references.html#id190"><span>McH13</span></a>]</span> assesses the
importance of metrics with the <span class="math notranslate nohighlight">\(\chi^2\)</span> statistic which is a
non-parametric statistical test of independence.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Import for Chi-sqaured-based feature selection technique</span>
<span class="kn">from</span> <span class="nn">sklearn.feature_selection</span> <span class="kn">import</span> <span class="n">SelectKBest</span><span class="p">,</span> <span class="n">chi2</span>

<span class="n">top_k</span> <span class="o">=</span> <span class="mi">3</span>
<span class="n">chi2_fs</span> <span class="o">=</span> <span class="n">SelectKBest</span><span class="p">(</span><span class="n">chi2</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="n">top_k</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">dfscores</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">chi2_fs</span><span class="o">.</span><span class="n">scores_</span><span class="p">)</span>
<span class="n">dfcolumns</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">features</span><span class="p">)</span>
<span class="c1">#concat two dataframes for better visualization </span>
<span class="n">featureScores</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">dfcolumns</span><span class="p">,</span><span class="n">dfscores</span><span class="p">],</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">featureScores</span><span class="o">.</span><span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;Feature&#39;</span><span class="p">,</span><span class="s1">&#39;Score&#39;</span><span class="p">]</span> 
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Top-k features (k =&#39;</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">top_k</span><span class="p">)</span><span class="o">+</span><span class="s1">&#39;) according to Chi-squared statistics are as follows:&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">featureScores</span><span class="o">.</span><span class="n">nlargest</span><span class="p">(</span><span class="n">top_k</span><span class="p">,</span><span class="s1">&#39;Score&#39;</span><span class="p">))</span> 
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Top-k features (k =3) according to Chi-squared statistics are as follows:
              Feature         Score
1            AddedLOC  26834.488115
2       nCoupledClass   1599.996258
4  CommentToCodeRatio     64.268658
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="wrapper-based-family">
<h3>Wrapper-based Family<a class="headerlink" href="#wrapper-based-family" title="Permalink to this headline">¶</a></h3>
<p>Wrapper-based feature selection
techniques <span id="id5">[<a class="reference internal" href="../references.html#id128"><span>JKP94</span></a>]</span><span id="id6">[<a class="reference internal" href="../references.html#id149"><span>KJ97</span></a>]</span> use classification
techniques to assess each subset of metrics and find the best subset of
metrics according to an evaluation criterion. Wrapper-based feature
selection is made up of three steps, which we described below.</p>
<p><em>(Step 1) Generate a subset of metrics.</em> Since it is impossible to
evaluate all possible subsets of metrics, wrapper-based feature
selection often uses search techniques (e.g., best first, greedy hill
climbing) to generate candidate subsets of metrics for evaluation.</p>
<p><em>(Step 2) Construct a classifier using a subset of metrics with a
predetermined classification technique.</em> Wrapper-based feature selection
constructs a classification model using a candidate subset of metrics
for a given classification technique (e.g., logistic regression and
random forest).</p>
<p><em>(Step 3) Evaluate the classifier according to a given evaluation
criterion.</em> Once the classifier is constructed, wrapper-based feature
selection evaluates the classifier using a given evaluation criterion
(e.g., Akaike Information Criterion).</p>
<p>For each candidate subset of metrics, wrapper-based feature selection
repeats Steps 2 and 3 in order to find the best subset of metrics
according to the evaluation criterion. Finally, it provides the best
subset of metrics that yields the highest performance according to the
evaluation criterion.</p>
<p><strong>Recursive Feature Elimination</strong> (RFE) <span id="id7">[<a class="reference internal" href="../references.html#id83"><span>GE03</span></a>]</span>
searches for the best subset of metrics by recursively eliminating the
least important metric. First, RFE constructs a model using all metrics
and ranks metrics according to their importance score (e.g., Breiman’s
Variable Importance for random forest). In each iteration, RFE excludes
the least important metric and reconstructs a model. Finally, RFE
provides the subset of metrics which yields the best performance
according to an evaluation criterion (e.g., AUC).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Feature Extraction with RFE</span>
<span class="kn">from</span> <span class="nn">sklearn.feature_selection</span> <span class="kn">import</span> <span class="n">RFE</span>
<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestClassifier</span>
<span class="kn">from</span> <span class="nn">itertools</span> <span class="kn">import</span> <span class="n">compress</span>
<span class="n">top_k</span> <span class="o">=</span> <span class="mi">3</span>
<span class="n">rf_model</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">1234</span><span class="p">,</span> <span class="n">n_jobs</span> <span class="o">=</span> <span class="mi">10</span><span class="p">)</span>
<span class="n">rfe</span> <span class="o">=</span> <span class="n">RFE</span><span class="p">(</span><span class="n">rf_model</span><span class="p">,</span> <span class="n">n_features_to_select</span> <span class="o">=</span> <span class="n">top_k</span><span class="p">)</span>
<span class="n">rfe_fit</span> <span class="o">=</span> <span class="n">rfe</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">rfe_features</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">compress</span><span class="p">(</span><span class="n">features</span><span class="p">,</span> <span class="n">rfe_fit</span><span class="o">.</span><span class="n">support_</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Top-k (k =&#39;</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">top_k</span><span class="p">)</span><span class="o">+</span><span class="s1">&#39;) according to the RFE teachnique are as follows:&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">rfe_features</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Top-k (k =3) according to the RFE teachnique are as follows:
[&#39;AddedLOC&#39;, &#39;nCoupledClass&#39;, &#39;CommentToCodeRatio&#39;]
</pre></div>
</div>
</div>
</div>
<p>Below, we provide an interactive tutorial to show that feature selection techniques may not mitigate collinearity and multicollinearity.</p>
<p>In this tutorial, we stimulate a multicollinearity situation of <code class="docutils literal notranslate"><span class="pre">AddedLOC</span></code>, <code class="docutils literal notranslate"><span class="pre">A</span></code>, and <code class="docutils literal notranslate"><span class="pre">B</span></code>.
However, all of these highly-correlated metrics with multicollinearity are selected by the Chi-squared feature selection technique.
In addition, according to the Recursive Feature Elimination technique, <code class="docutils literal notranslate"><span class="pre">A</span></code> and <code class="docutils literal notranslate"><span class="pre">B</span></code> are among the top-3 metrics that are selected.
These findings suggest that feature selection techniques may select highly-correlated metrics and do not mitigate collinearity and multicollinearity.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Prepare a dataframe for simulation</span>
<span class="n">X_simulation_train</span> <span class="o">=</span> <span class="n">add_constant</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>

<span class="c1"># Simulate a multicollinearity situation of AddedLOC, A, and B</span>
<span class="n">X_simulation_train</span><span class="p">[</span><span class="s1">&#39;A&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="mi">2</span> <span class="o">*</span> <span class="n">x_i</span> <span class="o">+</span> <span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">()</span> <span class="k">for</span> <span class="n">x_i</span> <span class="ow">in</span> <span class="n">X_simulation_train</span><span class="p">[</span><span class="s1">&#39;AddedLOC&#39;</span><span class="p">]]</span>
<span class="n">X_simulation_train</span><span class="p">[</span><span class="s1">&#39;B&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="mi">3</span> <span class="o">*</span> <span class="n">x_i</span> <span class="o">+</span> <span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">()</span> <span class="k">for</span> <span class="n">x_i</span> <span class="ow">in</span> <span class="n">X_simulation_train</span><span class="p">[</span><span class="s1">&#39;AddedLOC&#39;</span><span class="p">]]</span>

<span class="c1"># apply the Chi-squared feature selection technique</span>
<span class="n">top_k</span> <span class="o">=</span> <span class="mi">3</span>
<span class="n">chi2_fs</span> <span class="o">=</span> <span class="n">SelectKBest</span><span class="p">(</span><span class="n">chi2</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="n">top_k</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_simulation_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">dfscores</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">chi2_fs</span><span class="o">.</span><span class="n">scores_</span><span class="p">)</span>
<span class="n">dfcolumns</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">X_simulation_train</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span>
<span class="c1">#concat two dataframes for better visualization </span>
<span class="n">featureScores</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">dfcolumns</span><span class="p">,</span><span class="n">dfscores</span><span class="p">],</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">featureScores</span><span class="o">.</span><span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;Feature&#39;</span><span class="p">,</span><span class="s1">&#39;Score&#39;</span><span class="p">]</span> 
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Top-k features (k =&#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">top_k</span><span class="p">)</span> <span class="o">+</span><span class="s1">&#39;) according to Chi-squared statistics are as follows:&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">featureScores</span><span class="o">.</span><span class="n">nlargest</span><span class="p">(</span><span class="n">top_k</span><span class="p">,</span><span class="s1">&#39;Score&#39;</span><span class="p">))</span> 

<span class="c1"># apply the Recursive Feature Elimination technique</span>
<span class="n">rf_model</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">1234</span><span class="p">,</span> <span class="n">n_jobs</span> <span class="o">=</span> <span class="mi">10</span><span class="p">)</span>
<span class="n">rfe</span> <span class="o">=</span> <span class="n">RFE</span><span class="p">(</span><span class="n">rf_model</span><span class="p">,</span> <span class="n">n_features_to_select</span> <span class="o">=</span> <span class="n">top_k</span><span class="p">)</span>
<span class="n">rfe_fit</span> <span class="o">=</span> <span class="n">rfe</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_simulation_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">rfe_features</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">compress</span><span class="p">(</span><span class="n">X_simulation_train</span><span class="o">.</span><span class="n">columns</span><span class="p">,</span> <span class="n">rfe_fit</span><span class="o">.</span><span class="n">support_</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Top-k (k =&#39;</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">top_k</span><span class="p">)</span><span class="o">+</span><span class="s1">&#39;) according to the RFE teachnique are as follows:&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">rfe_features</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Top-k features (k =3) according to Chi-squared statistics are as follows:
    Feature         Score
7         B  80329.360766
6         A  53507.874728
2  AddedLOC  26834.488115
Top-k (k =3) according to the RFE teachnique are as follows:
[&#39;nCoupledClass&#39;, &#39;A&#39;, &#39;B&#39;]
</pre></div>
</div>
</div>
</div>
<p>To handle collinearity and multicollinearity, correlation analysis techniques (e.g., Spearman rank correlation test and Variance Inflation Factor analysis) should be used.
However, these correlation analysis techniques often involve manual process.
For example, in the above tutorial (Collinearity), the Spearman rank correlation test was used to measure the pair-wise correlation among metrics and presented using the heatmap plot.
In the tutorial, we found that <code class="docutils literal notranslate"><span class="pre">AddedLOC</span></code> and <code class="docutils literal notranslate"><span class="pre">A</span></code> are highly-correlated with the Spearman correlation of 1 (perfect correlation).
To mitigate this, we have to select one of them but the question is <em>Which one shoud be selected to mitigate collinearity?</em></p>
</div>
</div>
<div class="section" id="autospearman-an-automated-feature-selection-approach-that-address-collinearity-and-multicollinearity">
<h2><span class="section-number">1.4. </span>AutoSpearman: An automated feature selection approach that address collinearity and multicollinearity<a class="headerlink" href="#autospearman-an-automated-feature-selection-approach-that-address-collinearity-and-multicollinearity" title="Permalink to this headline">¶</a></h2>
<p>Jiarpakdee <em>et al.</em> <span id="id8">[<a class="reference internal" href="../references.html#id120"><span>JTT18a</span></a>]</span><span id="id9">[<a class="reference internal" href="../references.html#id124"><span>JTT20b</span></a>]</span> [&#64;jiarpakdee2018autospearman] introduce , an
automated metric selection approach based on the Spearman rank
correlation test and the VIF analysis for statistical inference.
The high-level concept of can be summarised into 2 parts:</p>
<p><em>(Part 1) Automatically select non-correlated metrics based on a
Spearman rank correlation test.</em> We first measure the correlation of all
metrics using the Spearman rank correlation test (<span class="math notranslate nohighlight">\(\rho\)</span>) (<em>cf.</em> Line
2). We use the interpretation of correlation coefficients (<span class="math notranslate nohighlight">\(|\rho|\)</span>) as
provided by Kraemer <span id="id10">[<a class="reference internal" href="../references.html#id152"><span>KML+03</span></a>]</span>—i.e., a Spearman
correlation coefficient of above or equal to 0.7 is considered a strong
correlation. Thus, we only consider the pairs that have an absolute
Spearman correlation coefficient of above or equal to the threshold
value (<span class="math notranslate nohighlight">\(sp.t\)</span>) of 0.7.</p>
<p>To automatically select non-correlated metrics based on the Spearman
rank correlation test, we start from the pair that has the highest
Spearman correlation coefficient. Since the two
correlated metrics under examination can be linearly predicted with each
other, one of these two metrics must be removed. Thus, we select the
metric that has the lowest average values of the absolute Spearman
correlation coefficients of the other metrics that are not included in
the pair. That means the removed metric is another metric
in the pair that is not selected. Since the removed
metric may be correlated with the other metrics, we remove any pairs of
metrics that are correlated with the removed metric.
Finally, we exclude the removed metric from the set of the remaining
metrics (<span class="math notranslate nohighlight">\(M'\)</span>). We repeat this process until all pairs of
metrics have their Spearman correlation coefficient below a threshold
value of 0.7.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Prepare a dataframe for AutoSpearman demo</span>
<span class="n">X_AS_train</span> <span class="o">=</span> <span class="n">X_train</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>

<span class="c1"># Simulate a multicollinearity situation of AddedLOC, A, and B</span>
<span class="n">X_AS_train</span><span class="p">[</span><span class="s1">&#39;A&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="mi">2</span> <span class="o">*</span> <span class="n">x_i</span> <span class="o">+</span> <span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">()</span> <span class="k">for</span> <span class="n">x_i</span> <span class="ow">in</span> <span class="n">X_AS_train</span><span class="p">[</span><span class="s1">&#39;AddedLOC&#39;</span><span class="p">]]</span>
<span class="n">X_AS_train</span><span class="p">[</span><span class="s1">&#39;B&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="mi">3</span> <span class="o">*</span> <span class="n">x_i</span> <span class="o">+</span> <span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">()</span> <span class="k">for</span> <span class="n">x_i</span> <span class="ow">in</span> <span class="n">X_AS_train</span><span class="p">[</span><span class="s1">&#39;AddedLOC&#39;</span><span class="p">]]</span>

<span class="n">AS_metrics</span> <span class="o">=</span> <span class="n">X_AS_train</span><span class="o">.</span><span class="n">columns</span>
<span class="n">count</span> <span class="o">=</span> <span class="mi">1</span>

<span class="c1"># (Part 1) Automatically select non-correlated metrics based on a Spearman rank correlation test.</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;(Part 1) Automatically select non-correlated metrics based on a Spearman rank correlation test&#39;</span><span class="p">)</span>
<span class="k">while</span> <span class="kc">True</span><span class="p">:</span>
    <span class="n">corrmat</span> <span class="o">=</span> <span class="n">X_AS_train</span><span class="o">.</span><span class="n">corr</span><span class="p">(</span><span class="n">method</span><span class="o">=</span><span class="s1">&#39;spearman&#39;</span><span class="p">)</span>
    <span class="n">top_corr_features</span> <span class="o">=</span> <span class="n">corrmat</span><span class="o">.</span><span class="n">index</span>
    <span class="n">abs_corrmat</span> <span class="o">=</span> <span class="nb">abs</span><span class="p">(</span><span class="n">corrmat</span><span class="p">)</span>
    
    <span class="c1"># identify correlated metrics with the correlation threshold of 0.7</span>
    <span class="n">highly_correlated_metrics</span> <span class="o">=</span> <span class="p">((</span><span class="n">corrmat</span> <span class="o">&gt;</span> <span class="o">.</span><span class="mi">7</span><span class="p">)</span> <span class="o">|</span> <span class="p">(</span><span class="n">corrmat</span> <span class="o">&lt;</span> <span class="o">-.</span><span class="mi">7</span><span class="p">))</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">corrmat</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">n_correlated_metrics</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">highly_correlated_metrics</span><span class="p">))</span>
    <span class="k">if</span> <span class="n">n_correlated_metrics</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="c1"># find the strongest pair-wise correlation</span>
        <span class="n">find_top_corr</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">melt</span><span class="p">(</span><span class="n">abs_corrmat</span><span class="p">,</span> <span class="n">ignore_index</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span>
        <span class="n">find_top_corr</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">inplace</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
        <span class="n">find_top_corr</span> <span class="o">=</span> <span class="n">find_top_corr</span><span class="p">[</span><span class="n">find_top_corr</span><span class="p">[</span><span class="s1">&#39;value&#39;</span><span class="p">]</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">]</span>
        <span class="n">top_corr_index</span> <span class="o">=</span> <span class="n">find_top_corr</span><span class="p">[</span><span class="s1">&#39;value&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">idxmax</span><span class="p">()</span>
        <span class="n">top_corr_i</span> <span class="o">=</span> <span class="n">find_top_corr</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">top_corr_index</span><span class="p">,</span> <span class="p">:]</span>

        <span class="c1"># get the 2 correlated metrics with the strongest correlation</span>
        <span class="n">correlated_metric_1</span> <span class="o">=</span> <span class="n">top_corr_i</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">correlated_metric_2</span> <span class="o">=</span> <span class="n">top_corr_i</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Step&#39;</span><span class="p">,</span> <span class="n">count</span><span class="p">,</span><span class="s1">&#39;comparing between&#39;</span><span class="p">,</span> <span class="n">correlated_metric_1</span><span class="p">,</span> <span class="s1">&#39;and&#39;</span><span class="p">,</span> <span class="n">correlated_metric_2</span><span class="p">)</span>
        
        <span class="c1"># compute their correlation with other metrics outside of the pair</span>
        <span class="n">correlation_with_other_metrics_1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">abs_corrmat</span><span class="p">[</span><span class="n">correlated_metric_1</span><span class="p">][[</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">top_corr_features</span> <span class="k">if</span> <span class="n">i</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span><span class="n">correlated_metric_1</span><span class="p">,</span> <span class="n">correlated_metric_2</span><span class="p">]]])</span>
        <span class="n">correlation_with_other_metrics_2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">abs_corrmat</span><span class="p">[</span><span class="n">correlated_metric_2</span><span class="p">][[</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">top_corr_features</span> <span class="k">if</span> <span class="n">i</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span><span class="n">correlated_metric_1</span><span class="p">,</span> <span class="n">correlated_metric_2</span><span class="p">]]])</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;&gt;&#39;</span><span class="p">,</span> <span class="n">correlated_metric_1</span><span class="p">,</span> <span class="s1">&#39;has the average correlation of&#39;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">correlation_with_other_metrics_1</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="s1">&#39;with other metrics&#39;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;&gt;&#39;</span><span class="p">,</span> <span class="n">correlated_metric_2</span><span class="p">,</span> <span class="s1">&#39;has the average correlation of&#39;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">correlation_with_other_metrics_2</span><span class="p">,</span><span class="mi">3</span><span class="p">)</span> <span class="p">,</span> <span class="s1">&#39;with other metrics&#39;</span><span class="p">)</span>
        <span class="c1"># select the metric that shares the least correlation outside of the pair and exclude the other</span>
        <span class="k">if</span> <span class="n">correlation_with_other_metrics_1</span> <span class="o">&lt;</span> <span class="n">correlation_with_other_metrics_2</span><span class="p">:</span>
            <span class="n">exclude_metric</span> <span class="o">=</span> <span class="n">correlated_metric_2</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">exclude_metric</span> <span class="o">=</span> <span class="n">correlated_metric_1</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;&gt;&#39;</span><span class="p">,</span> <span class="s1">&#39;Exclude&#39;</span><span class="p">,</span><span class="n">exclude_metric</span><span class="p">)</span>
        <span class="n">count</span> <span class="o">=</span> <span class="n">count</span><span class="o">+</span><span class="mi">1</span>
        <span class="n">AS_metrics</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">AS_metrics</span><span class="p">)</span> <span class="o">-</span> <span class="nb">set</span><span class="p">([</span><span class="n">exclude_metric</span><span class="p">]))</span>
        <span class="n">X_AS_train</span> <span class="o">=</span> <span class="n">X_AS_train</span><span class="p">[</span><span class="n">AS_metrics</span><span class="p">]</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">break</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;According to Part 1 of AutoSpearman,&#39;</span><span class="p">,</span> <span class="n">AS_metrics</span><span class="p">,</span><span class="s1">&#39;are selected.&#39;</span><span class="p">)</span>
<span class="n">generate_heatmap</span><span class="p">(</span><span class="n">X_AS_train</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(Part 1) Automatically select non-correlated metrics based on a Spearman rank correlation test
Step 1 comparing between A and AddedLOC
&gt; A has the average correlation of 0.382 with other metrics
&gt; AddedLOC has the average correlation of 0.387 with other metrics
&gt; Exclude AddedLOC
Step 2 comparing between A and B
&gt; A has the average correlation of 0.231 with other metrics
&gt; B has the average correlation of 0.235 with other metrics
&gt; Exclude B
According to Part 1 of AutoSpearman, [&#39;nCommit&#39;, &#39;CommentToCodeRatio&#39;, &#39;LOC&#39;, &#39;nCoupledClass&#39;, &#39;A&#39;] are selected.
</pre></div>
</div>
<img alt="../_images/correlation-analysis_16_1.png" src="../_images/correlation-analysis_16_1.png" />
</div>
</div>
<p><em>(Part 2) Automatically select non-correlated metrics based on a
Variance Inflation Factor analysis.</em> We first measure the magnitude of
multicollinearity of the remaining metrics (<span class="math notranslate nohighlight">\(M'\)</span>) from <code class="docutils literal notranslate"><span class="pre">Part</span> <span class="pre">1</span></code> using
the Variance Inflation Factor analysis (<em>cf.</em> Line 12). We use a VIF
threshold value (<span class="math notranslate nohighlight">\(vif.t\)</span>) of 5 to identify the presence of
multicollinearity, as suggested by Fox <span id="id11">[<a class="reference internal" href="../references.html#id70"><span>Fox15</span></a>]</span>.</p>
<p>To automatically remove correlated metrics from the Variance Inflation
Factor analysis, we identify the removed metric as the metric that has
the highest VIF score. We then exclude the removed
metric from the set of the remaining metrics (<span class="math notranslate nohighlight">\(M'\)</span>). We
apply the VIF analysis on the remaining metrics until none of the
remaining metrics have their VIF scores above or equal to the threshold
value. Finally,  produces a subset of non-correlated
metrics based on the Spearman rank correlation test and the VIF analysis
(<span class="math notranslate nohighlight">\(M'\)</span>).</p>
<p>Similar to filter-based feature selection techniques, <em>Part 1</em>
of  measures the correlation of all metrics using the Spearman rank
correlation test regardless of model construction. Similar to
wrapper-based feature selection techniques, <em>Part 2</em> of  constructs
regression models to measure the magnitude of multicollinearity of
metrics. Thus, we consider  as a hybrid feature selection technique
(both filter-based and wrapper-based).</p>
<p>TODO - include Tutorials for AutoSpearman</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Prepare a dataframe for VIF</span>
<span class="n">X_AS_train</span> <span class="o">=</span> <span class="n">add_constant</span><span class="p">(</span><span class="n">X_AS_train</span><span class="p">)</span>

<span class="n">selected_features</span> <span class="o">=</span> <span class="n">X_AS_train</span><span class="o">.</span><span class="n">columns</span>
<span class="n">count</span> <span class="o">=</span> <span class="mi">1</span>
<span class="c1"># (Part 2) Automatically select non-correlated metrics based on a Variance Inflation Factor analysis.</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;(Part 2) Automatically select non-correlated metrics based on a Variance Inflation Factor analysis&#39;</span><span class="p">)</span>
<span class="k">while</span> <span class="kc">True</span><span class="p">:</span>
    <span class="c1"># Calculate VIF scores</span>
    <span class="n">vif_scores</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">([</span><span class="n">variance_inflation_factor</span><span class="p">(</span><span class="n">X_AS_train</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span> 
                   <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">X_AS_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])],</span> 
                  <span class="n">index</span><span class="o">=</span><span class="n">X_AS_train</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span>
    <span class="c1"># Prepare a final dataframe of VIF scores</span>
    <span class="n">vif_scores</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">inplace</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
    <span class="n">vif_scores</span><span class="o">.</span><span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;Feature&#39;</span><span class="p">,</span> <span class="s1">&#39;VIFscore&#39;</span><span class="p">]</span>
    <span class="n">vif_scores</span> <span class="o">=</span> <span class="n">vif_scores</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">vif_scores</span><span class="p">[</span><span class="s1">&#39;Feature&#39;</span><span class="p">]</span> <span class="o">!=</span> <span class="s1">&#39;const&#39;</span><span class="p">,</span> <span class="p">:]</span>
    <span class="n">vif_scores</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">by</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;VIFscore&#39;</span><span class="p">],</span> <span class="n">ascending</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> <span class="n">inplace</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
    
    <span class="c1"># Find features that have their VIF scores of above 5.0</span>
    <span class="n">filtered_vif_scores</span> <span class="o">=</span> <span class="n">vif_scores</span><span class="p">[</span><span class="n">vif_scores</span><span class="p">[</span><span class="s1">&#39;VIFscore&#39;</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="mf">5.0</span><span class="p">]</span>
    
    <span class="c1"># Terminate when there is no features with the VIF scores of above 5.0</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">filtered_vif_scores</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">break</span>
        
    <span class="c1"># exclude the metric with the highest VIF score</span>
    <span class="n">metric_to_exclude</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">filtered_vif_scores</span><span class="p">[</span><span class="s1">&#39;Feature&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">1</span><span class="p">))[</span><span class="mi">0</span><span class="p">]</span>
    
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Step&#39;</span><span class="p">,</span> <span class="n">count</span><span class="p">,</span><span class="s1">&#39;- exclude&#39;</span><span class="p">,</span> <span class="nb">str</span><span class="p">(</span><span class="n">metric_to_exclude</span><span class="p">))</span>
    <span class="n">count</span> <span class="o">=</span> <span class="n">count</span> <span class="o">+</span> <span class="mi">1</span>
        
    <span class="n">selected_features</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">selected_features</span><span class="p">)</span> <span class="o">-</span> <span class="nb">set</span><span class="p">([</span><span class="n">metric_to_exclude</span><span class="p">]))</span>
    
    <span class="n">X_AS_train</span> <span class="o">=</span> <span class="n">X_AS_train</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="n">selected_features</span><span class="p">]</span>

    
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Finally, according to Part 2 of AutoSpearman,&#39;</span><span class="p">,</span> <span class="n">AS_metrics</span><span class="p">,</span><span class="s1">&#39;are selected.&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(Part 2) Automatically select non-correlated metrics based on a Variance Inflation Factor analysis
Finally, according to Part 2 of AutoSpearman, [&#39;nCommit&#39;, &#39;CommentToCodeRatio&#39;, &#39;LOC&#39;, &#39;nCoupledClass&#39;, &#39;A&#39;] are selected.
</pre></div>
</div>
</div>
</div>
<p>To foster future replication, we provide a python implementation of AutoSpearman as a function below.</p>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Import for AutoSpearman</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">from</span> <span class="nn">statsmodels.stats.outliers_influence</span> <span class="kn">import</span> <span class="n">variance_inflation_factor</span>
<span class="kn">from</span> <span class="nn">statsmodels.tools.tools</span> <span class="kn">import</span> <span class="n">add_constant</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    For more detail and citation, please refer to:</span>
<span class="sd">    [1] Jirayus Jiarpakdee, Chakkrit Tantithamthavorn, Christoph Treude:</span>
<span class="sd">    The Impact of Automated Feature Selection Techniques on the Interpretation of Defect Models. Empir. Softw. Eng. 25(5): 3590-3638 (2020)</span>

<span class="sd">    [2] Jirayus Jiarpakdee, Chakkrit Tantithamthavorn, Christoph Treude:</span>
<span class="sd">    AutoSpearman: Automatically Mitigating Correlated Software Metrics for Interpreting Defect Models. ICSME 2018: 92-103</span>
<span class="sd">&#39;&#39;&#39;</span>
<span class="k">def</span> <span class="nf">AutoSpearman</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">correlation_threshold</span> <span class="o">=</span> <span class="mf">0.7</span><span class="p">,</span> <span class="n">correlation_method</span> <span class="o">=</span> <span class="s1">&#39;spearman&#39;</span><span class="p">,</span> <span class="n">VIF_threshold</span> <span class="o">=</span> <span class="mi">5</span><span class="p">):</span>
    
    <span class="n">X_AS_train</span> <span class="o">=</span> <span class="n">X_train</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
    <span class="n">AS_metrics</span> <span class="o">=</span> <span class="n">X_AS_train</span><span class="o">.</span><span class="n">columns</span>
    <span class="n">count</span> <span class="o">=</span> <span class="mi">1</span>
    
    <span class="c1"># (Part 1) Automatically select non-correlated metrics based on a Spearman rank correlation test.</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;(Part 1) Automatically select non-correlated metrics based on a Spearman rank correlation test&#39;</span><span class="p">)</span>
    <span class="k">while</span> <span class="kc">True</span><span class="p">:</span>
        <span class="n">corrmat</span> <span class="o">=</span> <span class="n">X_AS_train</span><span class="o">.</span><span class="n">corr</span><span class="p">(</span><span class="n">method</span><span class="o">=</span><span class="n">correlation_method</span><span class="p">)</span>
        <span class="n">top_corr_features</span> <span class="o">=</span> <span class="n">corrmat</span><span class="o">.</span><span class="n">index</span>
        <span class="n">abs_corrmat</span> <span class="o">=</span> <span class="nb">abs</span><span class="p">(</span><span class="n">corrmat</span><span class="p">)</span>

        <span class="c1"># identify correlated metrics with the correlation threshold of the threshold</span>
        <span class="n">highly_correlated_metrics</span> <span class="o">=</span> <span class="p">((</span><span class="n">corrmat</span> <span class="o">&gt;</span> <span class="n">correlation_threshold</span><span class="p">)</span> <span class="o">|</span> <span class="p">(</span><span class="n">corrmat</span> <span class="o">&lt;</span> <span class="o">-</span><span class="n">correlation_threshold</span><span class="p">))</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">corrmat</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">n_correlated_metrics</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">highly_correlated_metrics</span><span class="p">))</span>
        <span class="k">if</span> <span class="n">n_correlated_metrics</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="c1"># find the strongest pair-wise correlation</span>
            <span class="n">find_top_corr</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">melt</span><span class="p">(</span><span class="n">abs_corrmat</span><span class="p">,</span> <span class="n">ignore_index</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span>
            <span class="n">find_top_corr</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">inplace</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
            <span class="n">find_top_corr</span> <span class="o">=</span> <span class="n">find_top_corr</span><span class="p">[</span><span class="n">find_top_corr</span><span class="p">[</span><span class="s1">&#39;value&#39;</span><span class="p">]</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">]</span>
            <span class="n">top_corr_index</span> <span class="o">=</span> <span class="n">find_top_corr</span><span class="p">[</span><span class="s1">&#39;value&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">idxmax</span><span class="p">()</span>
            <span class="n">top_corr_i</span> <span class="o">=</span> <span class="n">find_top_corr</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">top_corr_index</span><span class="p">,</span> <span class="p">:]</span>

            <span class="c1"># get the 2 correlated metrics with the strongest correlation</span>
            <span class="n">correlated_metric_1</span> <span class="o">=</span> <span class="n">top_corr_i</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="n">correlated_metric_2</span> <span class="o">=</span> <span class="n">top_corr_i</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
            <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;&gt; Step&#39;</span><span class="p">,</span> <span class="n">count</span><span class="p">,</span><span class="s1">&#39;comparing between&#39;</span><span class="p">,</span> <span class="n">correlated_metric_1</span><span class="p">,</span> <span class="s1">&#39;and&#39;</span><span class="p">,</span> <span class="n">correlated_metric_2</span><span class="p">)</span>

            <span class="c1"># compute their correlation with other metrics outside of the pair</span>
            <span class="n">correlation_with_other_metrics_1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">abs_corrmat</span><span class="p">[</span><span class="n">correlated_metric_1</span><span class="p">][[</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">top_corr_features</span> <span class="k">if</span> <span class="n">i</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span><span class="n">correlated_metric_1</span><span class="p">,</span> <span class="n">correlated_metric_2</span><span class="p">]]])</span>
            <span class="n">correlation_with_other_metrics_2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">abs_corrmat</span><span class="p">[</span><span class="n">correlated_metric_2</span><span class="p">][[</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">top_corr_features</span> <span class="k">if</span> <span class="n">i</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span><span class="n">correlated_metric_1</span><span class="p">,</span> <span class="n">correlated_metric_2</span><span class="p">]]])</span>
            <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;&gt;&gt;&#39;</span><span class="p">,</span> <span class="n">correlated_metric_1</span><span class="p">,</span> <span class="s1">&#39;has the average correlation of&#39;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">correlation_with_other_metrics_1</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="s1">&#39;with other metrics&#39;</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;&gt;&gt;&#39;</span><span class="p">,</span> <span class="n">correlated_metric_2</span><span class="p">,</span> <span class="s1">&#39;has the average correlation of&#39;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">correlation_with_other_metrics_2</span><span class="p">,</span><span class="mi">3</span><span class="p">)</span> <span class="p">,</span> <span class="s1">&#39;with other metrics&#39;</span><span class="p">)</span>
            <span class="c1"># select the metric that shares the least correlation outside of the pair and exclude the other</span>
            <span class="k">if</span> <span class="n">correlation_with_other_metrics_1</span> <span class="o">&lt;</span> <span class="n">correlation_with_other_metrics_2</span><span class="p">:</span>
                <span class="n">exclude_metric</span> <span class="o">=</span> <span class="n">correlated_metric_2</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">exclude_metric</span> <span class="o">=</span> <span class="n">correlated_metric_1</span>
            <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;&gt;&gt;&#39;</span><span class="p">,</span> <span class="s1">&#39;Exclude&#39;</span><span class="p">,</span><span class="n">exclude_metric</span><span class="p">)</span>
            <span class="n">count</span> <span class="o">=</span> <span class="n">count</span><span class="o">+</span><span class="mi">1</span>
            <span class="n">AS_metrics</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">AS_metrics</span><span class="p">)</span> <span class="o">-</span> <span class="nb">set</span><span class="p">([</span><span class="n">exclude_metric</span><span class="p">]))</span>
            <span class="n">X_AS_train</span> <span class="o">=</span> <span class="n">X_AS_train</span><span class="p">[</span><span class="n">AS_metrics</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">break</span>

    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;According to Part 1 of AutoSpearman,&#39;</span><span class="p">,</span> <span class="n">AS_metrics</span><span class="p">,</span><span class="s1">&#39;are selected.&#39;</span><span class="p">)</span>

    <span class="c1"># (Part 2) Automatically select non-correlated metrics based on a Variance Inflation Factor analysis.</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;(Part 2) Automatically select non-correlated metrics based on a Variance Inflation Factor analysis&#39;</span><span class="p">)</span>
    
    <span class="c1"># Prepare a dataframe for VIF</span>
    <span class="n">X_AS_train</span> <span class="o">=</span> <span class="n">add_constant</span><span class="p">(</span><span class="n">X_AS_train</span><span class="p">)</span>

    <span class="n">selected_features</span> <span class="o">=</span> <span class="n">X_AS_train</span><span class="o">.</span><span class="n">columns</span>
    <span class="n">count</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="k">while</span> <span class="kc">True</span><span class="p">:</span>
        <span class="c1"># Calculate VIF scores</span>
        <span class="n">vif_scores</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">([</span><span class="n">variance_inflation_factor</span><span class="p">(</span><span class="n">X_AS_train</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span> 
                       <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">X_AS_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])],</span> 
                      <span class="n">index</span><span class="o">=</span><span class="n">X_AS_train</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span>
        <span class="c1"># Prepare a final dataframe of VIF scores</span>
        <span class="n">vif_scores</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">inplace</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
        <span class="n">vif_scores</span><span class="o">.</span><span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;Feature&#39;</span><span class="p">,</span> <span class="s1">&#39;VIFscore&#39;</span><span class="p">]</span>
        <span class="n">vif_scores</span> <span class="o">=</span> <span class="n">vif_scores</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">vif_scores</span><span class="p">[</span><span class="s1">&#39;Feature&#39;</span><span class="p">]</span> <span class="o">!=</span> <span class="s1">&#39;const&#39;</span><span class="p">,</span> <span class="p">:]</span>
        <span class="n">vif_scores</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">by</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;VIFscore&#39;</span><span class="p">],</span> <span class="n">ascending</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> <span class="n">inplace</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>

        <span class="c1"># Find features that have their VIF scores of above the threshold</span>
        <span class="n">filtered_vif_scores</span> <span class="o">=</span> <span class="n">vif_scores</span><span class="p">[</span><span class="n">vif_scores</span><span class="p">[</span><span class="s1">&#39;VIFscore&#39;</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="n">VIF_threshold</span><span class="p">]</span>

        <span class="c1"># Terminate when there is no features with the VIF scores of above the threshold</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">filtered_vif_scores</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">break</span>

        <span class="c1"># exclude the metric with the highest VIF score</span>
        <span class="n">metric_to_exclude</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">filtered_vif_scores</span><span class="p">[</span><span class="s1">&#39;Feature&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">1</span><span class="p">))[</span><span class="mi">0</span><span class="p">]</span>

        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;&gt; Step&#39;</span><span class="p">,</span> <span class="n">count</span><span class="p">,</span><span class="s1">&#39;- exclude&#39;</span><span class="p">,</span> <span class="nb">str</span><span class="p">(</span><span class="n">metric_to_exclude</span><span class="p">))</span>
        <span class="n">count</span> <span class="o">=</span> <span class="n">count</span> <span class="o">+</span> <span class="mi">1</span>

        <span class="n">selected_features</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">selected_features</span><span class="p">)</span> <span class="o">-</span> <span class="nb">set</span><span class="p">([</span><span class="n">metric_to_exclude</span><span class="p">]))</span>

        <span class="n">X_AS_train</span> <span class="o">=</span> <span class="n">X_AS_train</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="n">selected_features</span><span class="p">]</span>


    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Finally, according to Part 2 of AutoSpearman,&#39;</span><span class="p">,</span> <span class="n">AS_metrics</span><span class="p">,</span><span class="s1">&#39;are selected.&#39;</span><span class="p">)</span>
    <span class="k">return</span><span class="p">(</span><span class="n">AS_metrics</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Parts of this chapter have been published by Jirayus Jiarpakdee, Chakkrit Tantithamthavorn, Ahmed E. Hassan: The Impact of Correlated Metrics on the Interpretation of Defect Models. IEEE Trans. Software Eng. 47(2): 320-331 (2021) <a class="reference external" href="https://doi.org/10.1109/TSE.2019.2891758">https://doi.org/10.1109/TSE.2019.2891758</a>”</p>
</div>
<div class="section" id="suggested-readings">
<h3>Suggested Readings<a class="headerlink" href="#suggested-readings" title="Permalink to this headline">¶</a></h3>
<p>[1] Jirayus Jiarpakdee, Chakkrit Tantithamthavorn, Ahmed E. Hassan: The Impact of Correlated Metrics on the Interpretation of Defect Models. IEEE Trans. Software Eng. 47(2): 320-331 (2021)</p>
<p>[2] Jirayus Jiarpakdee, Chakkrit Tantithamthavorn, Christoph Treude:
The Impact of Automated Feature Selection Techniques on the Interpretation of Defect Models. Empir. Softw. Eng. 25(5): 3590-3638 (2020)</p>
<p>[3] Jirayus Jiarpakdee, Chakkrit Tantithamthavorn, Christoph Treude:
AutoSpearman: Automatically Mitigating Correlated Software Metrics for Interpreting Defect Models. ICSME 2018: 92-103</p>
</div>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "xaitools"
        },
        kernelOptions: {
            kernelName: "xaitools",
            path: "./software-analytics"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'xaitools'</script>

              </div>
              
        
        <div class='prev-next-bottom'>
            
    <a class='left-prev' id="prev-link" href="../start/defect-prediction.html" title="previous page"><span class="section-number">3. </span>Defect Prediction Models</a>
    <a class='right-next' id="next-link" href="class-imbalance.html" title="next page"><span class="section-number">2. </span>Always handle class imbalance</a>

        </div>
        
        </div>
    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By Chakkrit Tantithamthavorn and Jirayus Jiarpakdee<br/>
        
            &copy; Copyright 2020.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>

    
  <script src="../_static/js/index.d3f166471bb80abb5163.js"></script>


    
  </body>
</html>